The project is for development and testing tokenizers in Rust.

The first tokenizer to implement is Byte Pair Encoding tokenizer. 

The next will be Word Piece and Sentence Piece Tokenizers. 

The project is in progress. In lib.rs there is collection of tools for 
file, string, collection of words preprocessing and vocabulary creation. 

Sample outputs: 


